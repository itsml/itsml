{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "controversial-conditions",
   "metadata": {},
   "source": [
    "# Deep-learning-based denoising and reconstruction of superresolution structured illumination microscopy images\n",
    "\n",
    "\n",
    "\n",
    "# Motivation and problem description\n",
    "\n",
    "Super-resolution structured illumination microscopy (SR-SIM) can provide up to two times spatial resolution of fluorescently labeled samples. Reconstruction of high-quality SR-SIM images depends critically on the various sinusoidal illumination patterns with high modulation contrast. However, there is a crucial trade-off between the spatial resolution of the raw SIM samples and the low exposure times. When the biological sample is illuminated with low excitation power, the raw SIM samples result in low SNR. To address this critical problem, we demonstrate here the end-to-end deep learning-based denoising and reconstruction of noisy raw SIM images into high-resolution SR-SIM images. The proposed SR-REDSIM method generalizes very well across different noise levels and different microscopic settings. Moreover, this method also proves to be very robust to image reconstruction artifacts.\n",
    "\n",
    "\n",
    "# Solution\n",
    "\n",
    "There are several reconstruction algorithms that convert the raw SIM images into SR-SIM images. However, these algorithms are not able to reconstruct a high-quality super-resolution image from noisy raw SIM images. The SR-REDSIM reconstruction algorithm is a complete Deep Learning based end-to-end method that can be used to reconstruct and denoise the noisy raw SIM images. The complete pipeline of SR-REDSIM is shown in the following figure [1]. From Fig. 1, it can be seen that the stack of 15 raw noisy SIM images (three angles with five phases each) with a size of 512×512 pixels [i.e., the stack dimensions were 15×512×512 (frame, width, height)] is provided as input. The algorithm produces a high-quality SR-SIM image with a size of 1024×1024 pixels as output.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-beach",
   "metadata": {},
   "source": [
    "\n",
    "![title](SRREDSIMPipeline.png)[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-hawaii",
   "metadata": {},
   "source": [
    "# Loading module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tracked-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, time, datetime, shutil, pickle,argparse, json\n",
    "import SRDataGenerator\n",
    "import sys\n",
    "from SRREDModel import SRREDNet,UNet \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-acrobat",
   "metadata": {},
   "source": [
    "# Loading and preparation of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-compiler",
   "metadata": {},
   "source": [
    "This module will load the training and test sample images. The training and test input images are enclosed in the form of stacks where each stack further contains 15 frames of noisy raw SIM images (i.e., 15 images from 5 different phases and 3 orientations) along with high-quality SR-SIM samples as output or ground-truth images. The high-quality SR-SIM images are reconstructed by using the conventional fairSIM reconstruction algorithm [2]. Once the data is loaded, it is further normalized and reshaped according to the requirements. The normalization function will enforce randomness in the training and test data, however, it is not mandatory as the Keras fit function internally shuffles the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadPreprocessedData(imageDir, randomization):\n",
    "\n",
    "\n",
    "    print('Loading Data')\n",
    "    \n",
    "    trainxPath= os.path.join(imageDir,'TrainStack_x')\n",
    "    trainyPath=os.path.join(imageDir,'Train_y')\n",
    "    testxPath= os.path.join(imageDir,'TestStack_x')\n",
    "    testyPath= os.path.join(imageDir,'Test_y')\n",
    "        \n",
    "    trainXpath= SRDataGenerator.ExtractPath(trainxPath)\n",
    "    trainYpath= SRDataGenerator.ExtractPath(trainyPath)\n",
    "    testXpath= SRDataGenerator.ExtractPath(testxPath)\n",
    "    testYpath= SRDataGenerator.ExtractPath(testyPath)\n",
    "    \n",
    "        \n",
    "    print('Loading Images')\n",
    "    trainDataX= SRDataGenerator.LoadImages(trainXpath)\n",
    "    trainDataY= SRDataGenerator.LoadImages(trainYpath)\n",
    "    testDataX= SRDataGenerator.LoadImages(testXpath)\n",
    "    testDataY= SRDataGenerator.LoadImages(testYpath)\n",
    "    \n",
    "    \n",
    "    # Scale images down to [0,1] for following operations\n",
    "    trainDataX = SRDataGenerator.ImageNormalization(trainDataX[:5])\n",
    "    trainDataY = SRDataGenerator.ImageNormalization(trainDataY[:5])\n",
    "    \n",
    "    testDataX = SRDataGenerator.ImageNormalization(testDataX[:5])\n",
    "    testDataY = SRDataGenerator.ImageNormalization(testDataY[:5])\n",
    "\n",
    "\n",
    "    \n",
    "    if randomization:\n",
    "        print ('Randomization is done')\n",
    "        trainDataX, trainDataY = Randomization(trainDataX, trainDataY)\n",
    "        testDataX, testDataY = Randomization(testDataX, testDataY)\n",
    "    else:\n",
    "        print ('Data is not Randomized')\n",
    "        \n",
    "\n",
    "    trainDataX, trainDataY= SRDataGenerator.ReshapeData(trainDataX, trainDataY)\n",
    "    \n",
    "    testDataX, testDataY= SRDataGenerator.ReshapeData(testDataX, testDataY)   \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    return trainDataX, trainDataY, testDataX, testDataY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-armenia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainDataX, trainDataY, testDataX, testDataY=LoadPreprocessedData('/home/shah/FHBI-Shares/Projects/ML4Nanoscopy/SR-REDSIM-Data', False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-consolidation",
   "metadata": {},
   "source": [
    "Let's have a look at the stack of noisy raw input images and the reference image. Even the ground truth image exhibits reconstruction artifacts, therefore it is named as \"reference image\".\n",
    "\n",
    "![title](outputsample.png)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-dairy",
   "metadata": {},
   "source": [
    "# Super-Resolution model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-award",
   "metadata": {},
   "source": [
    "SR-REDSIM is based on a modified version of RED-Net. The SR-REDSIM architecture consists of three blocks: the encoder, the decoder, and the upsampling block. SR-REDSIM contains a total of 44 convolutional and deconvolutional layers with symmetric skip connections. The encoder block is composed of 21 convolutional layers, whereas the decoder contains 21 deconvolutional layers. The upsampling block consists of two deconvolutional layers that perform the upsampling task by adjusting the size of the stride. The SR-REDSIM model provides the best results after training the model for 100 epochs.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-timothy",
   "metadata": {},
   "source": [
    "![title](SR-REDSIMarchitecture.png)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-dominant",
   "metadata": {},
   "source": [
    "# Training configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-apparatus",
   "metadata": {},
   "source": [
    "Before loading the model we can change some of the important parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "collect-letters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1024, 1024,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 1024, 1024, 6 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 1024, 1024, 6 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1024, 1024, 6 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 1024, 1024, 6 36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 1024, 1024, 6 36928       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 1024, 1024, 6 36928       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 1024, 1024, 6 36928       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 1024, 1024, 6 36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1024, 1024, 6 36928       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 1024, 1024, 6 36928       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 1024, 1024, 6 36928       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1024, 1024, 6 0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1024, 1024, 6 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 1024, 1024, 6 36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 1024, 1024, 6 36928       conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1024, 1024, 6 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1024, 1024, 6 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 1024, 1024, 6 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 1024, 1024, 6 36928       conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1024, 1024, 6 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1024, 1024, 6 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 1024, 1024, 6 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 1024, 1024, 6 36928       conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1024, 1024, 6 0           conv2d_transpose_6[0][0]         \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1024, 1024, 6 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 1024, 1024, 6 36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 1024, 1024, 6 36928       conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1024, 1024, 6 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1024, 1024, 6 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 1024, 1024, 6 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 1024, 1024, 6 36928       conv2d_transpose_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1024, 1024, 6 0           conv2d_transpose_10[0][0]        \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1024, 1024, 6 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 1024, 1024, 6 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 1024, 1024, 6 36928       conv2d_transpose_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 1024, 1024, 6 0           conv2d_transpose_12[0][0]        \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1024, 1024, 6 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 1024, 1024, 6 36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 1024, 1024, 6 36928       conv2d_transpose_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1024, 1024, 6 0           conv2d_transpose_14[0][0]        \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1024, 1024, 6 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 1024, 1024, 6 36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DTran (None, 1024, 1024, 6 36928       conv2d_transpose_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1024, 1024, 6 0           conv2d_transpose_16[0][0]        \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1024, 1024, 6 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DTran (None, 1024, 1024, 6 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DTran (None, 1024, 1024, 6 36928       conv2d_transpose_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1024, 1024, 6 0           conv2d_transpose_18[0][0]        \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1024, 1024, 6 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DTran (None, 1024, 1024, 6 36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DTran (None, 1024, 1024, 6 36928       conv2d_transpose_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DTran (None, 2048, 2048, 6 36928       conv2d_transpose_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DTran (None, 2048, 2048, 1 577         conv2d_transpose_21[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,552,193\n",
      "Trainable params: 1,552,193\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ImageWidth, ImageHeight, channel =1024,1024 ,1\n",
    "NumberofKernels=64\n",
    "sizeofKernel=3\n",
    "padding='same'\n",
    "stride=1\n",
    "activation='relu'\n",
    "Loss=\"mean_squared_error\"\n",
    "model=SRREDNet(ImageWidth, ImageHeight, channel,NumberofKernels,sizeofKernel,padding,stride, activation)\n",
    "model=model.buildDNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-pennsylvania",
   "metadata": {},
   "source": [
    "#  Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-incident",
   "metadata": {},
   "source": [
    "For the training of the model for this super-resolution task, it is recommended to use multiple GPUs in order to speed up the training process. Normally, the training process for 100 epochs requires 12-15 hours with two Nvidia Tesla P100 graphics cards. The training process can be monitored by inspecting the convergence of the loss function value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model')\n",
    "# Build model with cpu\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "with strategy.scope():\n",
    "    model.summary()\n",
    "    compileDNN(model, Loss)\n",
    "    \n",
    "trainingModel = model.fit(trainDataX, trainDataY, validation_data=(testDataX, testDataY),\n",
    "                                        batch_size=2, epochs=2, verbose=1, initial_epoch=0)\n",
    "trainingEvaluation = model.evaluate(trainDataX, trainDataY, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-memorial",
   "metadata": {},
   "source": [
    "#  Analysis of the predicted image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-belize",
   "metadata": {},
   "source": [
    "It can be clearly seen that the trained model generalizes well on the stack of the unseen noisy raw input SIM samples and generates high-resolution SR-SIM images. The predicted image below on the right side shows a very smooth cell structure and does not show any reconstruction artifacts whereas in the reference image in the middle, grainy noise is very prominent in the filaments of the cell structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-agreement",
   "metadata": {},
   "source": [
    "![title](result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-longitude",
   "metadata": {},
   "source": [
    "# Export Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-cholesterol",
   "metadata": {},
   "source": [
    "Once the training process is finished, the trained model will be stored at the specified location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingModel.save('path to save model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-panic",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-chinese",
   "metadata": {},
   "source": [
    "[1] Zafran Hussain Shah, Marcel Müller, Tung-Cheng Wang, Philip Maurice Scheidig, Axel Schneider, Mark Schüttpelz, Thomas Huser, and Wolfram Schenck, \"Deep-learning based denoising and reconstruction of super-resolution structured illumination microscopy images,\" Photon. Res. 9, B168-B181 (2021)\n",
    "\n",
    "[2] M. Müller, V. Mönkemöller, S. Hennig, W. Hübner, and T. Huser, “Open-source image reconstruction of super-resolution structured illumination microscopy data in ImageJ,” Nat. Commun. 7, 10980 (2016).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
